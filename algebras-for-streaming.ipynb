{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// put the spark install from the base notebook image onto Ammonite's classpath\n",
    "java.nio.file.Files.list(java.nio.file.Paths.get(\"/opt/spark/jars\")).toArray.map(_.toString).foreach { fname =>\n",
    "  val path = java.nio.file.FileSystems.getDefault().getPath(fname)\n",
    "  val x = ammonite.ops.Path(path)\n",
    "  interp.load.cp(x)\n",
    "}\n",
    "// Load the ammonite-spark package to get AmmoniteSparkSession\n",
    "import $ivy.`sh.almond::ammonite-spark:0.1.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                             \u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql-kafka-0-10:2.2.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                                \u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//import $ivy.`org.isarnproject::isarn-sketches-spark:0.3.1-sp2.2-py2.7`\n",
    "import $ivy.`org.isarnproject::isarn-sketches-spark:0.3.1-topk-1-sp2.2-py2.7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting spark JARs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (org.eclipse.jetty.util.log).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "18/09/27 17:57:52 INFO SparkContext: Running Spark version 2.2.0\n",
      "18/09/27 17:57:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "18/09/27 17:57:52 INFO SparkContext: Submitted application: 28da45ca-7f94-464c-a632-6e2985e4b08f\n",
      "18/09/27 17:57:52 INFO SecurityManager: Changing view acls to: 1000130000\n",
      "18/09/27 17:57:52 INFO SecurityManager: Changing modify acls to: 1000130000\n",
      "18/09/27 17:57:52 INFO SecurityManager: Changing view acls groups to: \n",
      "18/09/27 17:57:52 INFO SecurityManager: Changing modify acls groups to: \n",
      "18/09/27 17:57:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(1000130000); groups with view permissions: Set(); users  with modify permissions: Set(1000130000); groups with modify permissions: Set()\n",
      "18/09/27 17:57:53 INFO Utils: Successfully started service 'sparkDriver' on port 35101.\n",
      "18/09/27 17:57:53 INFO SparkEnv: Registering MapOutputTracker\n",
      "18/09/27 17:57:53 INFO SparkEnv: Registering BlockManagerMaster\n",
      "18/09/27 17:57:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "18/09/27 17:57:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "18/09/27 17:57:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-693c8c63-1209-47c2-bded-759624743540\n",
      "18/09/27 17:57:53 INFO MemoryStore: MemoryStore started with capacity 1909.8 MB\n",
      "18/09/27 17:57:53 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "18/09/27 17:57:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "18/09/27 17:57:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.17.0.10:4040\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/upickle_2.11/0.6.6/upickle_2.11-0.6.6.jar at spark://172.17.0.10:35101/jars/upickle_2.11-0.6.6.jar with timestamp 1538071073630\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.11/1.0.0/fastparse_2.11-1.0.0.jar at spark://172.17.0.10:35101/jars/fastparse_2.11-1.0.0.jar with timestamp 1538071073631\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/jline/jline-terminal/3.6.2/jline-terminal-3.6.2.jar at spark://172.17.0.10:35101/jars/jline-terminal-3.6.2.jar with timestamp 1538071073632\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.11.12/0.1.7/scala-kernel-api_2.11.12-0.1.7.jar at spark://172.17.0.10:35101/jars/scala-kernel-api_2.11.12-0.1.7.jar with timestamp 1538071073632\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/coursier_2.11/1.1.0-M7/coursier_2.11-1.1.0-M7.jar at spark://172.17.0.10:35101/jars/coursier_2.11-1.1.0-M7.jar with timestamp 1538071073632\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar at spark://172.17.0.10:35101/jars/javassist-3.21.0-GA.jar with timestamp 1538071073633\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scalaj/scalaj-http_2.11/2.4.0/scalaj-http_2.11-2.4.0.jar at spark://172.17.0.10:35101/jars/scalaj-http_2.11-2.4.0.jar with timestamp 1538071073633\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.11/0.2.4/fansi_2.11-0.2.4.jar at spark://172.17.0.10:35101/jars/fansi_2.11-0.2.4.jar with timestamp 1538071073633\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.11/0.1.4/sourcecode_2.11-0.1.4.jar at spark://172.17.0.10:35101/jars/sourcecode_2.11-0.1.4.jar with timestamp 1538071073634\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/scopt/scopt_2.11/3.5.0/scopt_2.11-3.5.0.jar at spark://172.17.0.10:35101/jars/scopt_2.11-3.5.0.jar with timestamp 1538071073634\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/jline/jline-reader/3.6.2/jline-reader-3.6.2.jar at spark://172.17.0.10:35101/jars/jline-reader-3.6.2.jar with timestamp 1538071073634\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/net/java/dev/jna/jna/4.2.2/jna-4.2.2.jar at spark://172.17.0.10:35101/jars/jna-4.2.2.jar with timestamp 1538071073634\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp_2.11.12/1.1.2-37-53fcfcd/ammonite-interp_2.11.12-1.1.2-37-53fcfcd.jar at spark://172.17.0.10:35101/jars/ammonite-interp_2.11.12-1.1.2-37-53fcfcd.jar with timestamp 1538071073635\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl_2.11.12/1.1.2-37-53fcfcd/ammonite-repl_2.11.12-1.1.2-37-53fcfcd.jar at spark://172.17.0.10:35101/jars/ammonite-repl_2.11.12-1.1.2-37-53fcfcd.jar with timestamp 1538071073635\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.11/1.1.2-37-53fcfcd/ammonite-util_2.11-1.1.2-37-53fcfcd.jar at spark://172.17.0.10:35101/jars/ammonite-util_2.11-1.1.2-37-53fcfcd.jar with timestamp 1538071073635\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.11/0.5.2/pprint_2.11-0.5.2.jar at spark://172.17.0.10:35101/jars/pprint_2.11-0.5.2.jar with timestamp 1538071073636\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-ops_2.11/1.1.2-37-53fcfcd/ammonite-ops_2.11-1.1.2-37-53fcfcd.jar at spark://172.17.0.10:35101/jars/ammonite-ops_2.11-1.1.2-37-53fcfcd.jar with timestamp 1538071073636\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/io/get-coursier/coursier-cache_2.11/1.1.0-M7/coursier-cache_2.11-1.1.0-M7.jar at spark://172.17.0.10:35101/jars/coursier-cache_2.11-1.1.0-M7.jar with timestamp 1538071073636\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-runtime_2.11/1.1.2-37-53fcfcd/ammonite-runtime_2.11-1.1.2-37-53fcfcd.jar at spark://172.17.0.10:35101/jars/ammonite-runtime_2.11-1.1.2-37-53fcfcd.jar with timestamp 1538071073636\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.11/0.1.2/geny_2.11-0.1.2.jar at spark://172.17.0.10:35101/jars/geny_2.11-0.1.2.jar with timestamp 1538071073637\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.11/1.0.0/scalaparse_2.11-1.0.0.jar at spark://172.17.0.10:35101/jars/scalaparse_2.11-1.0.0.jar with timestamp 1538071073637\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-terminal_2.11/1.1.2-37-53fcfcd/ammonite-terminal_2.11-1.1.2-37-53fcfcd.jar at spark://172.17.0.10:35101/jars/ammonite-terminal_2.11-1.1.2-37-53fcfcd.jar with timestamp 1538071073637\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.11/0.1.7/interpreter-api_2.11-0.1.7.jar at spark://172.17.0.10:35101/jars/interpreter-api_2.11-0.1.7.jar with timestamp 1538071073637\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse-utils_2.11/1.0.0/fastparse-utils_2.11-1.0.0.jar at spark://172.17.0.10:35101/jars/fastparse-utils_2.11-1.0.0.jar with timestamp 1538071073638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.11/1.1.0/scala-xml_2.11-1.1.0.jar at spark://172.17.0.10:35101/jars/scala-xml_2.11-1.1.0.jar with timestamp 1538071073638\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/jline/jline-terminal-jna/3.6.2/jline-terminal-jna-3.6.2.jar at spark://172.17.0.10:35101/jars/jline-terminal-jna-3.6.2.jar with timestamp 1538071073638\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/lihaoyi/ujson_2.11/0.6.6/ujson_2.11-0.6.6.jar at spark://172.17.0.10:35101/jars/ujson_2.11-0.6.6.jar with timestamp 1538071073639\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.5/javaparser-core-3.2.5.jar at spark://172.17.0.10:35101/jars/javaparser-core-3.2.5.jar with timestamp 1538071073639\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/home/nbuser/.local/share/jupyter/kernels/scala/launcher.jar at spark://172.17.0.10:35101/jars/launcher.jar with timestamp 1538071073639\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-continuation/8.1.14.v20131031/jetty-continuation-8.1.14.v20131031.jar at spark://172.17.0.10:35101/jars/jetty-continuation-8.1.14.v20131031.jar with timestamp 1538071073640\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/8.1.14.v20131031/jetty-http-8.1.14.v20131031.jar at spark://172.17.0.10:35101/jars/jetty-http-8.1.14.v20131031.jar with timestamp 1538071073640\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar at spark://172.17.0.10:35101/jars/jetty-server-8.1.14.v20131031.jar with timestamp 1538071073640\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.1.1/ammonite-spark_2.11-0.1.1.jar at spark://172.17.0.10:35101/jars/ammonite-spark_2.11-0.1.1.jar with timestamp 1538071073640\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/8.1.14.v20131031/jetty-io-8.1.14.v20131031.jar at spark://172.17.0.10:35101/jars/jetty-io-8.1.14.v20131031.jar with timestamp 1538071073641\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar at spark://172.17.0.10:35101/jars/jetty-util-8.1.14.v20131031.jar with timestamp 1538071073641\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/JavaEWAH-0.3.2.jar at spark://172.17.0.10:35101/jars/JavaEWAH-0.3.2.jar with timestamp 1538071073642\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/RoaringBitmap-0.5.11.jar at spark://172.17.0.10:35101/jars/RoaringBitmap-0.5.11.jar with timestamp 1538071073642\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/ST4-4.0.4.jar at spark://172.17.0.10:35101/jars/ST4-4.0.4.jar with timestamp 1538071073642\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/activation-1.1.1.jar at spark://172.17.0.10:35101/jars/activation-1.1.1.jar with timestamp 1538071073643\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/antlr-2.7.7.jar at spark://172.17.0.10:35101/jars/antlr-2.7.7.jar with timestamp 1538071073643\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/antlr-runtime-3.4.jar at spark://172.17.0.10:35101/jars/antlr-runtime-3.4.jar with timestamp 1538071073643\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/antlr4-runtime-4.5.3.jar at spark://172.17.0.10:35101/jars/antlr4-runtime-4.5.3.jar with timestamp 1538071073643\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/aopalliance-1.0.jar at spark://172.17.0.10:35101/jars/aopalliance-1.0.jar with timestamp 1538071073644\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/aopalliance-repackaged-2.4.0-b34.jar at spark://172.17.0.10:35101/jars/aopalliance-repackaged-2.4.0-b34.jar with timestamp 1538071073644\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/apache-log4j-extras-1.2.17.jar at spark://172.17.0.10:35101/jars/apache-log4j-extras-1.2.17.jar with timestamp 1538071073644\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/apacheds-i18n-2.0.0-M15.jar at spark://172.17.0.10:35101/jars/apacheds-i18n-2.0.0-M15.jar with timestamp 1538071073645\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/apacheds-kerberos-codec-2.0.0-M15.jar at spark://172.17.0.10:35101/jars/apacheds-kerberos-codec-2.0.0-M15.jar with timestamp 1538071073645\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/api-asn1-api-1.0.0-M20.jar at spark://172.17.0.10:35101/jars/api-asn1-api-1.0.0-M20.jar with timestamp 1538071073645\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/api-util-1.0.0-M20.jar at spark://172.17.0.10:35101/jars/api-util-1.0.0-M20.jar with timestamp 1538071073646\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/arpack_combined_all-0.1.jar at spark://172.17.0.10:35101/jars/arpack_combined_all-0.1.jar with timestamp 1538071073646\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/avro-1.7.7.jar at spark://172.17.0.10:35101/jars/avro-1.7.7.jar with timestamp 1538071073649\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/avro-ipc-1.7.7.jar at spark://172.17.0.10:35101/jars/avro-ipc-1.7.7.jar with timestamp 1538071073650\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/avro-mapred-1.7.7-hadoop2.jar at spark://172.17.0.10:35101/jars/avro-mapred-1.7.7-hadoop2.jar with timestamp 1538071073653\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/base64-2.3.8.jar at spark://172.17.0.10:35101/jars/base64-2.3.8.jar with timestamp 1538071073659\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/bcprov-jdk15on-1.51.jar at spark://172.17.0.10:35101/jars/bcprov-jdk15on-1.51.jar with timestamp 1538071073661\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/bonecp-0.8.0.RELEASE.jar at spark://172.17.0.10:35101/jars/bonecp-0.8.0.RELEASE.jar with timestamp 1538071073662\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/breeze-macros_2.11-0.13.1.jar at spark://172.17.0.10:35101/jars/breeze-macros_2.11-0.13.1.jar with timestamp 1538071073664\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/breeze_2.11-0.13.1.jar at spark://172.17.0.10:35101/jars/breeze_2.11-0.13.1.jar with timestamp 1538071073666\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/calcite-avatica-1.2.0-incubating.jar at spark://172.17.0.10:35101/jars/calcite-avatica-1.2.0-incubating.jar with timestamp 1538071073668\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/calcite-core-1.2.0-incubating.jar at spark://172.17.0.10:35101/jars/calcite-core-1.2.0-incubating.jar with timestamp 1538071073673\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/calcite-linq4j-1.2.0-incubating.jar at spark://172.17.0.10:35101/jars/calcite-linq4j-1.2.0-incubating.jar with timestamp 1538071073674\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/chill-java-0.8.0.jar at spark://172.17.0.10:35101/jars/chill-java-0.8.0.jar with timestamp 1538071073676\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/chill_2.11-0.8.0.jar at spark://172.17.0.10:35101/jars/chill_2.11-0.8.0.jar with timestamp 1538071073678\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-beanutils-1.7.0.jar at spark://172.17.0.10:35101/jars/commons-beanutils-1.7.0.jar with timestamp 1538071073680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-beanutils-core-1.8.0.jar at spark://172.17.0.10:35101/jars/commons-beanutils-core-1.8.0.jar with timestamp 1538071073683\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-cli-1.2.jar at spark://172.17.0.10:35101/jars/commons-cli-1.2.jar with timestamp 1538071073686\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-codec-1.10.jar at spark://172.17.0.10:35101/jars/commons-codec-1.10.jar with timestamp 1538071073687\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-collections-3.2.2.jar at spark://172.17.0.10:35101/jars/commons-collections-3.2.2.jar with timestamp 1538071073690\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-compiler-3.0.0.jar at spark://172.17.0.10:35101/jars/commons-compiler-3.0.0.jar with timestamp 1538071073691\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-compress-1.4.1.jar at spark://172.17.0.10:35101/jars/commons-compress-1.4.1.jar with timestamp 1538071073693\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-configuration-1.6.jar at spark://172.17.0.10:35101/jars/commons-configuration-1.6.jar with timestamp 1538071073697\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-crypto-1.0.0.jar at spark://172.17.0.10:35101/jars/commons-crypto-1.0.0.jar with timestamp 1538071073698\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-dbcp-1.4.jar at spark://172.17.0.10:35101/jars/commons-dbcp-1.4.jar with timestamp 1538071073700\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-digester-1.8.jar at spark://172.17.0.10:35101/jars/commons-digester-1.8.jar with timestamp 1538071073701\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-httpclient-3.1.jar at spark://172.17.0.10:35101/jars/commons-httpclient-3.1.jar with timestamp 1538071073706\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-io-2.4.jar at spark://172.17.0.10:35101/jars/commons-io-2.4.jar with timestamp 1538071073709\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-lang-2.6.jar at spark://172.17.0.10:35101/jars/commons-lang-2.6.jar with timestamp 1538071073711\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-lang3-3.5.jar at spark://172.17.0.10:35101/jars/commons-lang3-3.5.jar with timestamp 1538071073712\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-logging-1.1.3.jar at spark://172.17.0.10:35101/jars/commons-logging-1.1.3.jar with timestamp 1538071073714\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-math3-3.4.1.jar at spark://172.17.0.10:35101/jars/commons-math3-3.4.1.jar with timestamp 1538071073716\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-net-2.2.jar at spark://172.17.0.10:35101/jars/commons-net-2.2.jar with timestamp 1538071073720\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/commons-pool-1.5.4.jar at spark://172.17.0.10:35101/jars/commons-pool-1.5.4.jar with timestamp 1538071073721\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/compress-lzf-1.0.3.jar at spark://172.17.0.10:35101/jars/compress-lzf-1.0.3.jar with timestamp 1538071073724\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/core-1.1.2.jar at spark://172.17.0.10:35101/jars/core-1.1.2.jar with timestamp 1538071073726\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/curator-client-2.6.0.jar at spark://172.17.0.10:35101/jars/curator-client-2.6.0.jar with timestamp 1538071073727\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/curator-framework-2.6.0.jar at spark://172.17.0.10:35101/jars/curator-framework-2.6.0.jar with timestamp 1538071073729\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/curator-recipes-2.6.0.jar at spark://172.17.0.10:35101/jars/curator-recipes-2.6.0.jar with timestamp 1538071073730\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/datanucleus-api-jdo-3.2.6.jar at spark://172.17.0.10:35101/jars/datanucleus-api-jdo-3.2.6.jar with timestamp 1538071073731\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/datanucleus-core-3.2.10.jar at spark://172.17.0.10:35101/jars/datanucleus-core-3.2.10.jar with timestamp 1538071073732\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/datanucleus-rdbms-3.2.9.jar at spark://172.17.0.10:35101/jars/datanucleus-rdbms-3.2.9.jar with timestamp 1538071073734\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/derby-10.12.1.1.jar at spark://172.17.0.10:35101/jars/derby-10.12.1.1.jar with timestamp 1538071073738\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/eigenbase-properties-1.1.5.jar at spark://172.17.0.10:35101/jars/eigenbase-properties-1.1.5.jar with timestamp 1538071073740\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/gson-2.2.4.jar at spark://172.17.0.10:35101/jars/gson-2.2.4.jar with timestamp 1538071073745\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/guava-14.0.1.jar at spark://172.17.0.10:35101/jars/guava-14.0.1.jar with timestamp 1538071073745\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/guice-3.0.jar at spark://172.17.0.10:35101/jars/guice-3.0.jar with timestamp 1538071073746\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/guice-servlet-3.0.jar at spark://172.17.0.10:35101/jars/guice-servlet-3.0.jar with timestamp 1538071073749\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-annotations-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-annotations-2.7.3.jar with timestamp 1538071073752\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-auth-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-auth-2.7.3.jar with timestamp 1538071073754\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-client-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-client-2.7.3.jar with timestamp 1538071073755\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-common-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-common-2.7.3.jar with timestamp 1538071073757\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-hdfs-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-hdfs-2.7.3.jar with timestamp 1538071073759\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-mapreduce-client-app-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-mapreduce-client-app-2.7.3.jar with timestamp 1538071073760\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-mapreduce-client-common-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-mapreduce-client-common-2.7.3.jar with timestamp 1538071073763\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-mapreduce-client-core-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-mapreduce-client-core-2.7.3.jar with timestamp 1538071073765\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar with timestamp 1538071073767\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar with timestamp 1538071073769\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-yarn-api-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-yarn-api-2.7.3.jar with timestamp 1538071073771\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-yarn-client-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-yarn-client-2.7.3.jar with timestamp 1538071073776\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-yarn-common-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-yarn-common-2.7.3.jar with timestamp 1538071073778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-yarn-server-common-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-yarn-server-common-2.7.3.jar with timestamp 1538071073780\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hadoop-yarn-server-web-proxy-2.7.3.jar at spark://172.17.0.10:35101/jars/hadoop-yarn-server-web-proxy-2.7.3.jar with timestamp 1538071073782\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hive-beeline-1.2.1.spark2.jar at spark://172.17.0.10:35101/jars/hive-beeline-1.2.1.spark2.jar with timestamp 1538071073786\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hive-cli-1.2.1.spark2.jar at spark://172.17.0.10:35101/jars/hive-cli-1.2.1.spark2.jar with timestamp 1538071073787\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hive-exec-1.2.1.spark2.jar at spark://172.17.0.10:35101/jars/hive-exec-1.2.1.spark2.jar with timestamp 1538071073789\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hive-jdbc-1.2.1.spark2.jar at spark://172.17.0.10:35101/jars/hive-jdbc-1.2.1.spark2.jar with timestamp 1538071073790\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hive-metastore-1.2.1.spark2.jar at spark://172.17.0.10:35101/jars/hive-metastore-1.2.1.spark2.jar with timestamp 1538071073791\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hk2-api-2.4.0-b34.jar at spark://172.17.0.10:35101/jars/hk2-api-2.4.0-b34.jar with timestamp 1538071073795\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hk2-locator-2.4.0-b34.jar at spark://172.17.0.10:35101/jars/hk2-locator-2.4.0-b34.jar with timestamp 1538071073796\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/hk2-utils-2.4.0-b34.jar at spark://172.17.0.10:35101/jars/hk2-utils-2.4.0-b34.jar with timestamp 1538071073797\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/htrace-core-3.1.0-incubating.jar at spark://172.17.0.10:35101/jars/htrace-core-3.1.0-incubating.jar with timestamp 1538071073798\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/httpclient-4.5.2.jar at spark://172.17.0.10:35101/jars/httpclient-4.5.2.jar with timestamp 1538071073800\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/httpcore-4.4.4.jar at spark://172.17.0.10:35101/jars/httpcore-4.4.4.jar with timestamp 1538071073801\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/ivy-2.4.0.jar at spark://172.17.0.10:35101/jars/ivy-2.4.0.jar with timestamp 1538071073802\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-annotations-2.6.5.jar at spark://172.17.0.10:35101/jars/jackson-annotations-2.6.5.jar with timestamp 1538071073803\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-core-2.6.5.jar at spark://172.17.0.10:35101/jars/jackson-core-2.6.5.jar with timestamp 1538071073806\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-core-asl-1.9.13.jar at spark://172.17.0.10:35101/jars/jackson-core-asl-1.9.13.jar with timestamp 1538071073806\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-databind-2.6.5.jar at spark://172.17.0.10:35101/jars/jackson-databind-2.6.5.jar with timestamp 1538071073807\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-jaxrs-1.9.13.jar at spark://172.17.0.10:35101/jars/jackson-jaxrs-1.9.13.jar with timestamp 1538071073810\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-mapper-asl-1.9.13.jar at spark://172.17.0.10:35101/jars/jackson-mapper-asl-1.9.13.jar with timestamp 1538071073810\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-module-paranamer-2.6.5.jar at spark://172.17.0.10:35101/jars/jackson-module-paranamer-2.6.5.jar with timestamp 1538071073811\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-module-scala_2.11-2.6.5.jar at spark://172.17.0.10:35101/jars/jackson-module-scala_2.11-2.6.5.jar with timestamp 1538071073812\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jackson-xc-1.9.13.jar at spark://172.17.0.10:35101/jars/jackson-xc-1.9.13.jar with timestamp 1538071073813\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/janino-3.0.0.jar at spark://172.17.0.10:35101/jars/janino-3.0.0.jar with timestamp 1538071073816\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/java-xmlbuilder-1.0.jar at spark://172.17.0.10:35101/jars/java-xmlbuilder-1.0.jar with timestamp 1538071073818\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/javassist-3.18.1-GA.jar at spark://172.17.0.10:35101/jars/javassist-3.18.1-GA.jar with timestamp 1538071073820\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/javax.annotation-api-1.2.jar at spark://172.17.0.10:35101/jars/javax.annotation-api-1.2.jar with timestamp 1538071073822\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/javax.inject-1.jar at spark://172.17.0.10:35101/jars/javax.inject-1.jar with timestamp 1538071073824\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/javax.inject-2.4.0-b34.jar at spark://172.17.0.10:35101/jars/javax.inject-2.4.0-b34.jar with timestamp 1538071073825\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/javax.servlet-api-3.1.0.jar at spark://172.17.0.10:35101/jars/javax.servlet-api-3.1.0.jar with timestamp 1538071073826\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/javax.ws.rs-api-2.0.1.jar at spark://172.17.0.10:35101/jars/javax.ws.rs-api-2.0.1.jar with timestamp 1538071073829\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/javolution-5.5.1.jar at spark://172.17.0.10:35101/jars/javolution-5.5.1.jar with timestamp 1538071073831\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jaxb-api-2.2.2.jar at spark://172.17.0.10:35101/jars/jaxb-api-2.2.2.jar with timestamp 1538071073834\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jcl-over-slf4j-1.7.16.jar at spark://172.17.0.10:35101/jars/jcl-over-slf4j-1.7.16.jar with timestamp 1538071073835\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jdo-api-3.0.1.jar at spark://172.17.0.10:35101/jars/jdo-api-3.0.1.jar with timestamp 1538071073837\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jersey-client-2.22.2.jar at spark://172.17.0.10:35101/jars/jersey-client-2.22.2.jar with timestamp 1538071073839\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jersey-common-2.22.2.jar at spark://172.17.0.10:35101/jars/jersey-common-2.22.2.jar with timestamp 1538071073840\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jersey-container-servlet-2.22.2.jar at spark://172.17.0.10:35101/jars/jersey-container-servlet-2.22.2.jar with timestamp 1538071073842\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jersey-container-servlet-core-2.22.2.jar at spark://172.17.0.10:35101/jars/jersey-container-servlet-core-2.22.2.jar with timestamp 1538071073843\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jersey-guava-2.22.2.jar at spark://172.17.0.10:35101/jars/jersey-guava-2.22.2.jar with timestamp 1538071073845\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jersey-media-jaxb-2.22.2.jar at spark://172.17.0.10:35101/jars/jersey-media-jaxb-2.22.2.jar with timestamp 1538071073846\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jersey-server-2.22.2.jar at spark://172.17.0.10:35101/jars/jersey-server-2.22.2.jar with timestamp 1538071073848\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jets3t-0.9.3.jar at spark://172.17.0.10:35101/jars/jets3t-0.9.3.jar with timestamp 1538071073849\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jetty-6.1.26.jar at spark://172.17.0.10:35101/jars/jetty-6.1.26.jar with timestamp 1538071073850\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jetty-util-6.1.26.jar at spark://172.17.0.10:35101/jars/jetty-util-6.1.26.jar with timestamp 1538071073852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jline-2.12.1.jar at spark://172.17.0.10:35101/jars/jline-2.12.1.jar with timestamp 1538071073854\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/joda-time-2.9.3.jar at spark://172.17.0.10:35101/jars/joda-time-2.9.3.jar with timestamp 1538071073859\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jodd-core-3.5.2.jar at spark://172.17.0.10:35101/jars/jodd-core-3.5.2.jar with timestamp 1538071073862\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jpam-1.1.jar at spark://172.17.0.10:35101/jars/jpam-1.1.jar with timestamp 1538071073865\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/json4s-ast_2.11-3.2.11.jar at spark://172.17.0.10:35101/jars/json4s-ast_2.11-3.2.11.jar with timestamp 1538071073867\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/json4s-core_2.11-3.2.11.jar at spark://172.17.0.10:35101/jars/json4s-core_2.11-3.2.11.jar with timestamp 1538071073870\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/json4s-jackson_2.11-3.2.11.jar at spark://172.17.0.10:35101/jars/json4s-jackson_2.11-3.2.11.jar with timestamp 1538071073872\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jsp-api-2.1.jar at spark://172.17.0.10:35101/jars/jsp-api-2.1.jar with timestamp 1538071073873\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jsr305-1.3.9.jar at spark://172.17.0.10:35101/jars/jsr305-1.3.9.jar with timestamp 1538071073874\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jta-1.1.jar at spark://172.17.0.10:35101/jars/jta-1.1.jar with timestamp 1538071073876\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jtransforms-2.4.0.jar at spark://172.17.0.10:35101/jars/jtransforms-2.4.0.jar with timestamp 1538071073877\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/jul-to-slf4j-1.7.16.jar at spark://172.17.0.10:35101/jars/jul-to-slf4j-1.7.16.jar with timestamp 1538071073878\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/kryo-shaded-3.0.3.jar at spark://172.17.0.10:35101/jars/kryo-shaded-3.0.3.jar with timestamp 1538071073881\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/leveldbjni-all-1.8.jar at spark://172.17.0.10:35101/jars/leveldbjni-all-1.8.jar with timestamp 1538071073882\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/libfb303-0.9.3.jar at spark://172.17.0.10:35101/jars/libfb303-0.9.3.jar with timestamp 1538071073884\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/libthrift-0.9.3.jar at spark://172.17.0.10:35101/jars/libthrift-0.9.3.jar with timestamp 1538071073888\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/log4j-1.2.17.jar at spark://172.17.0.10:35101/jars/log4j-1.2.17.jar with timestamp 1538071073889\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/lz4-1.3.0.jar at spark://172.17.0.10:35101/jars/lz4-1.3.0.jar with timestamp 1538071073892\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/machinist_2.11-0.6.1.jar at spark://172.17.0.10:35101/jars/machinist_2.11-0.6.1.jar with timestamp 1538071073893\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/macro-compat_2.11-1.1.1.jar at spark://172.17.0.10:35101/jars/macro-compat_2.11-1.1.1.jar with timestamp 1538071073895\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/mail-1.4.7.jar at spark://172.17.0.10:35101/jars/mail-1.4.7.jar with timestamp 1538071073898\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/mesos-1.0.0-shaded-protobuf.jar at spark://172.17.0.10:35101/jars/mesos-1.0.0-shaded-protobuf.jar with timestamp 1538071073903\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/metrics-core-3.1.2.jar at spark://172.17.0.10:35101/jars/metrics-core-3.1.2.jar with timestamp 1538071073905\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/metrics-graphite-3.1.2.jar at spark://172.17.0.10:35101/jars/metrics-graphite-3.1.2.jar with timestamp 1538071073906\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/metrics-json-3.1.2.jar at spark://172.17.0.10:35101/jars/metrics-json-3.1.2.jar with timestamp 1538071073909\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/metrics-jvm-3.1.2.jar at spark://172.17.0.10:35101/jars/metrics-jvm-3.1.2.jar with timestamp 1538071073911\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/minlog-1.3.0.jar at spark://172.17.0.10:35101/jars/minlog-1.3.0.jar with timestamp 1538071073913\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/mx4j-3.0.2.jar at spark://172.17.0.10:35101/jars/mx4j-3.0.2.jar with timestamp 1538071073913\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/netty-3.9.9.Final.jar at spark://172.17.0.10:35101/jars/netty-3.9.9.Final.jar with timestamp 1538071073914\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/netty-all-4.0.43.Final.jar at spark://172.17.0.10:35101/jars/netty-all-4.0.43.Final.jar with timestamp 1538071073916\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/objenesis-2.1.jar at spark://172.17.0.10:35101/jars/objenesis-2.1.jar with timestamp 1538071073917\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/opencsv-2.3.jar at spark://172.17.0.10:35101/jars/opencsv-2.3.jar with timestamp 1538071073919\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/oro-2.0.8.jar at spark://172.17.0.10:35101/jars/oro-2.0.8.jar with timestamp 1538071073919\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/osgi-resource-locator-1.0.1.jar at spark://172.17.0.10:35101/jars/osgi-resource-locator-1.0.1.jar with timestamp 1538071073921\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/paranamer-2.6.jar at spark://172.17.0.10:35101/jars/paranamer-2.6.jar with timestamp 1538071073922\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/parquet-column-1.8.2.jar at spark://172.17.0.10:35101/jars/parquet-column-1.8.2.jar with timestamp 1538071073923\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/parquet-common-1.8.2.jar at spark://172.17.0.10:35101/jars/parquet-common-1.8.2.jar with timestamp 1538071073924\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/parquet-encoding-1.8.2.jar at spark://172.17.0.10:35101/jars/parquet-encoding-1.8.2.jar with timestamp 1538071073925\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/parquet-format-2.3.1.jar at spark://172.17.0.10:35101/jars/parquet-format-2.3.1.jar with timestamp 1538071073927\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/parquet-hadoop-1.8.2.jar at spark://172.17.0.10:35101/jars/parquet-hadoop-1.8.2.jar with timestamp 1538071073928\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/parquet-hadoop-bundle-1.6.0.jar at spark://172.17.0.10:35101/jars/parquet-hadoop-bundle-1.6.0.jar with timestamp 1538071073929\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/parquet-jackson-1.8.2.jar at spark://172.17.0.10:35101/jars/parquet-jackson-1.8.2.jar with timestamp 1538071073930\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/pmml-model-1.2.15.jar at spark://172.17.0.10:35101/jars/pmml-model-1.2.15.jar with timestamp 1538071073931\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/pmml-schema-1.2.15.jar at spark://172.17.0.10:35101/jars/pmml-schema-1.2.15.jar with timestamp 1538071073932\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/protobuf-java-2.5.0.jar at spark://172.17.0.10:35101/jars/protobuf-java-2.5.0.jar with timestamp 1538071073934\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/py4j-0.10.4.jar at spark://172.17.0.10:35101/jars/py4j-0.10.4.jar with timestamp 1538071073935\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/pyrolite-4.13.jar at spark://172.17.0.10:35101/jars/pyrolite-4.13.jar with timestamp 1538071073936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/scala-compiler-2.11.8.jar at spark://172.17.0.10:35101/jars/scala-compiler-2.11.8.jar with timestamp 1538071073937\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/scala-library-2.11.8.jar at spark://172.17.0.10:35101/jars/scala-library-2.11.8.jar with timestamp 1538071073939\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/scala-parser-combinators_2.11-1.0.4.jar at spark://172.17.0.10:35101/jars/scala-parser-combinators_2.11-1.0.4.jar with timestamp 1538071073941\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/scala-reflect-2.11.8.jar at spark://172.17.0.10:35101/jars/scala-reflect-2.11.8.jar with timestamp 1538071073942\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/scala-xml_2.11-1.0.2.jar at spark://172.17.0.10:35101/jars/scala-xml_2.11-1.0.2.jar with timestamp 1538071073949\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/scalap-2.11.8.jar at spark://172.17.0.10:35101/jars/scalap-2.11.8.jar with timestamp 1538071073951\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/shapeless_2.11-2.3.2.jar at spark://172.17.0.10:35101/jars/shapeless_2.11-2.3.2.jar with timestamp 1538071073953\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/slf4j-api-1.7.16.jar at spark://172.17.0.10:35101/jars/slf4j-api-1.7.16.jar with timestamp 1538071073954\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/slf4j-log4j12-1.7.16.jar at spark://172.17.0.10:35101/jars/slf4j-log4j12-1.7.16.jar with timestamp 1538071073955\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/snappy-0.2.jar at spark://172.17.0.10:35101/jars/snappy-0.2.jar with timestamp 1538071073957\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/snappy-java-1.1.2.6.jar at spark://172.17.0.10:35101/jars/snappy-java-1.1.2.6.jar with timestamp 1538071073964\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-catalyst_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-catalyst_2.11-2.2.0.jar with timestamp 1538071073971\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-core_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-core_2.11-2.2.0.jar with timestamp 1538071073984\n",
      "18/09/27 17:57:53 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-graphx_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-graphx_2.11-2.2.0.jar with timestamp 1538071073993\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-hive-thriftserver_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-hive-thriftserver_2.11-2.2.0.jar with timestamp 1538071074004\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-hive_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-hive_2.11-2.2.0.jar with timestamp 1538071074004\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-launcher_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-launcher_2.11-2.2.0.jar with timestamp 1538071074006\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-mesos_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-mesos_2.11-2.2.0.jar with timestamp 1538071074009\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-mllib-local_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-mllib-local_2.11-2.2.0.jar with timestamp 1538071074012\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-mllib_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-mllib_2.11-2.2.0.jar with timestamp 1538071074014\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-network-common_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-network-common_2.11-2.2.0.jar with timestamp 1538071074015\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-network-shuffle_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-network-shuffle_2.11-2.2.0.jar with timestamp 1538071074016\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-repl_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-repl_2.11-2.2.0.jar with timestamp 1538071074016\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-sketch_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-sketch_2.11-2.2.0.jar with timestamp 1538071074018\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-sql_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-sql_2.11-2.2.0.jar with timestamp 1538071074020\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-streaming_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-streaming_2.11-2.2.0.jar with timestamp 1538071074026\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-tags_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-tags_2.11-2.2.0.jar with timestamp 1538071074027\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-unsafe_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-unsafe_2.11-2.2.0.jar with timestamp 1538071074030\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spark-yarn_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-yarn_2.11-2.2.0.jar with timestamp 1538071074031\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spire-macros_2.11-0.13.0.jar at spark://172.17.0.10:35101/jars/spire-macros_2.11-0.13.0.jar with timestamp 1538071074033\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/spire_2.11-0.13.0.jar at spark://172.17.0.10:35101/jars/spire_2.11-0.13.0.jar with timestamp 1538071074035\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/stax-api-1.0-2.jar at spark://172.17.0.10:35101/jars/stax-api-1.0-2.jar with timestamp 1538071074050\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/stax-api-1.0.1.jar at spark://172.17.0.10:35101/jars/stax-api-1.0.1.jar with timestamp 1538071074055\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/stream-2.7.0.jar at spark://172.17.0.10:35101/jars/stream-2.7.0.jar with timestamp 1538071074062\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/stringtemplate-3.2.1.jar at spark://172.17.0.10:35101/jars/stringtemplate-3.2.1.jar with timestamp 1538071074066\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/super-csv-2.2.0.jar at spark://172.17.0.10:35101/jars/super-csv-2.2.0.jar with timestamp 1538071074075\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/univocity-parsers-2.2.1.jar at spark://172.17.0.10:35101/jars/univocity-parsers-2.2.1.jar with timestamp 1538071074080\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/validation-api-1.1.0.Final.jar at spark://172.17.0.10:35101/jars/validation-api-1.1.0.Final.jar with timestamp 1538071074082\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/xbean-asm5-shaded-4.4.jar at spark://172.17.0.10:35101/jars/xbean-asm5-shaded-4.4.jar with timestamp 1538071074088\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/xercesImpl-2.9.1.jar at spark://172.17.0.10:35101/jars/xercesImpl-2.9.1.jar with timestamp 1538071074093\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/xmlenc-0.52.jar at spark://172.17.0.10:35101/jars/xmlenc-0.52.jar with timestamp 1538071074094\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/xz-1.0.jar at spark://172.17.0.10:35101/jars/xz-1.0.jar with timestamp 1538071074099\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/jars/zookeeper-3.4.6.jar at spark://172.17.0.10:35101/jars/zookeeper-3.4.6.jar with timestamp 1538071074109\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/kafka/kafka-clients/0.10.0.1/kafka-clients-0.10.0.1.jar at spark://172.17.0.10:35101/jars/kafka-clients-0.10.0.1.jar with timestamp 1538071074119\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.11/2.2.0/spark-sql-kafka-0-10_2.11-2.2.0.jar at spark://172.17.0.10:35101/jars/spark-sql-kafka-0-10_2.11-2.2.0.jar with timestamp 1538071074145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar at spark://172.17.0.10:35101/jars/slf4j-api-1.7.21.jar with timestamp 1538071074150\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/isarnproject/isarn-sketches_2.11/0.1.2/isarn-sketches_2.11-0.1.2.jar at spark://172.17.0.10:35101/jars/isarn-sketches_2.11-0.1.2.jar with timestamp 1538071074157\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/isarnproject/isarn-algebra-api_2.11/0.0.3/isarn-algebra-api_2.11-0.0.3.jar at spark://172.17.0.10:35101/jars/isarn-algebra-api_2.11-0.0.3.jar with timestamp 1538071074158\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/isarnproject/isarn-sketches-spark_2.11/0.3.1-topk-1-sp2.2-py2.7/isarn-sketches-spark_2.11-0.3.1-topk-1-sp2.2-py2.7.jar at spark://172.17.0.10:35101/jars/isarn-sketches-spark_2.11-0.3.1-topk-1-sp2.2-py2.7.jar with timestamp 1538071074159\n",
      "18/09/27 17:57:54 INFO SparkContext: Added JAR file:/opt/spark/.cache/coursier/v1/https/repo1.maven.org/maven2/org/isarnproject/isarn-collections_2.11/0.0.4/isarn-collections_2.11-0.0.4.jar at spark://172.17.0.10:35101/jars/isarn-collections_2.11-0.0.4.jar with timestamp 1538071074163\n",
      "18/09/27 17:57:54 INFO Executor: Starting executor ID driver on host localhost\n",
      "18/09/27 17:57:54 INFO Executor: Using REPL class URI: http://172.17.0.10:40291\n",
      "18/09/27 17:57:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33773.\n",
      "18/09/27 17:57:54 INFO NettyBlockTransferService: Server created on 172.17.0.10:33773\n",
      "18/09/27 17:57:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "18/09/27 17:57:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.17.0.10, 33773, None)\n",
      "18/09/27 17:57:54 INFO BlockManagerMasterEndpoint: Registering block manager 172.17.0.10:33773 with 1909.8 MB RAM, BlockManagerId(driver, 172.17.0.10, 33773, None)\n",
      "18/09/27 17:57:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.17.0.10, 33773, None)\n",
      "18/09/27 17:57:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.17.0.10, 33773, None)\n",
      "18/09/27 17:57:54 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/notebooks/spark-warehouse/').\n",
      "18/09/27 17:57:54 INFO SharedState: Warehouse path is 'file:/notebooks/spark-warehouse/'.\n",
      "18/09/27 17:57:55 WARN SharedState: URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory\n",
      "18/09/27 17:57:55 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@54bc942"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "val spark = {\n",
    "    AmmoniteSparkSession.builder()\n",
    "      .master(\"local[2]\")\n",
    "      .getOrCreate()\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.sqlContext.implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.streaming.Trigger\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.isarnproject.sketches._, org.isarnproject.sketches.udaf._, org.apache.spark.isarnproject.sketches.udt._\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.sqlContext.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.expressions._\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "import org.isarnproject.sketches._, org.isarnproject.sketches.udaf._, org.apache.spark.isarnproject.sketches.udt._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mappender\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mlog4j\u001b[39m.\u001b[32mConsoleAppender\u001b[39m = org.apache.log4j.ConsoleAppender@a9effc9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val appender = org.apache.log4j.Logger.getRootLogger().getAppender(\"console\").asInstanceOf[org.apache.log4j.ConsoleAppender]\n",
    "appender.setThreshold(org.apache.log4j.Level.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres6_0\u001b[39m: \u001b[32mUserDefinedFunction\u001b[39m = \u001b[33mUserDefinedFunction\u001b[39m(\n",
       "  <function1>,\n",
       "  IntegerType,\n",
       "  \u001b[33mSome\u001b[39m(\u001b[33mList\u001b[39m(StringType))\n",
       ")\n",
       "\u001b[36msketchCDF\u001b[39m: \u001b[32mTDigestUDAF\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mTDigestUDAF\u001b[39m(\u001b[32m0.2\u001b[39m, \u001b[32m25\u001b[39m)\n",
       "\u001b[36mres6_2\u001b[39m: \u001b[32mUserDefinedFunction\u001b[39m = \u001b[33mUserDefinedFunction\u001b[39m(<function1>, DoubleType, \u001b[32mNone\u001b[39m)\n",
       "\u001b[36mres6_3\u001b[39m: \u001b[32mUserDefinedFunction\u001b[39m = \u001b[33mUserDefinedFunction\u001b[39m(<function1>, DoubleType, \u001b[32mNone\u001b[39m)\n",
       "\u001b[36mres6_4\u001b[39m: \u001b[32mUserDefinedFunction\u001b[39m = \u001b[33mUserDefinedFunction\u001b[39m(<function1>, DoubleType, \u001b[32mNone\u001b[39m)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"wordcount\", (text: String)=>text.split(\" \").filter(_.length > 0).length)\n",
    "val sketchCDF = tdigestUDAF[Double].delta(0.2).maxDiscrete(25)\n",
    "spark.udf.register(\"p50\", (c:Any)=>c.asInstanceOf[TDigestSQL].tdigest.cdfInverse(0.5))\n",
    "spark.udf.register(\"p90\", (c:Any)=>c.asInstanceOf[TDigestSQL].tdigest.cdfInverse(0.9))\n",
    "spark.udf.register(\"p99\", (c:Any)=>c.asInstanceOf[TDigestSQL].tdigest.cdfInverse(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [key: binary, value: binary ... 5 more fields]\n",
       "\u001b[36mvalues\u001b[39m: \u001b[32mDataFrame\u001b[39m = [value: string]\n",
       "\u001b[36mstructure\u001b[39m: \u001b[32mStructType\u001b[39m = \u001b[33mStructType\u001b[39m(\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"text\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"user_id\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"update_id\"\u001b[39m, StringType, true, {})\n",
       ")\n",
       "\u001b[36mrecords\u001b[39m: \u001b[32mDataFrame\u001b[39m = [user_id: string, text: string ... 1 more field]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\n",
    "  .option(\"subscribe\", \"social-firehose\")\n",
    "  .load()\n",
    "val values = df.select(($\"value\").cast(StringType))\n",
    "val structure = StructType(Seq(\"text\",\"user_id\",\"update_id\").map{f=>StructField(f, StringType, true)})\n",
    "val records = values.select(from_json($\"value\", structure).alias(\"json\"))\n",
    "    .select($\"json.user_id\", $\"json.text\")\n",
    "    .select($\"user_id\",\n",
    "            $\"text\",\n",
    "            callUDF(\"wordcount\", $\"text\").alias(\"wordcount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------+---+\n",
      "|user_id|avg|\n",
      "+-------+---+\n",
      "+-------+---+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----------+----+\n",
      "|   user_id| avg|\n",
      "+----------+----+\n",
      "|3384408632|40.0|\n",
      "|7076610942|19.0|\n",
      "|1656582676|18.0|\n",
      "|0253301460|16.0|\n",
      "|1853980848|15.0|\n",
      "|9680421532|14.0|\n",
      "|3237646542|14.0|\n",
      "|2741764075|12.0|\n",
      "|0072980186|11.0|\n",
      "|4150606001|10.0|\n",
      "|8826969164| 9.0|\n",
      "|6969222767| 8.0|\n",
      "+----------+----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----------+----+\n",
      "|   user_id| avg|\n",
      "+----------+----+\n",
      "|3384408632|40.0|\n",
      "|8963165417|37.0|\n",
      "|3556776499|32.0|\n",
      "|0368331941|24.0|\n",
      "|1996606479|21.0|\n",
      "|0556078341|20.0|\n",
      "|7929052071|20.0|\n",
      "|7076610942|19.0|\n",
      "|5591035376|19.0|\n",
      "|1656582676|18.0|\n",
      "|3144537041|16.0|\n",
      "|0253301460|16.0|\n",
      "|1853980848|15.0|\n",
      "|7253011876|15.0|\n",
      "|7011988820|15.0|\n",
      "|9680421532|14.0|\n",
      "|3237646542|14.0|\n",
      "|2741764075|12.0|\n",
      "|8542212533|11.0|\n",
      "|0072980186|11.0|\n",
      "+----------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+----------+----+\n",
      "|   user_id| avg|\n",
      "+----------+----+\n",
      "|3384408632|40.0|\n",
      "|8963165417|37.0|\n",
      "|3556776499|32.0|\n",
      "|7644786464|24.0|\n",
      "|0368331941|24.0|\n",
      "|5857946936|23.0|\n",
      "|6747444099|22.0|\n",
      "|8550450250|21.0|\n",
      "|1996606479|21.0|\n",
      "|0556078341|20.0|\n",
      "|7929052071|20.0|\n",
      "|7076610942|19.0|\n",
      "|5591035376|19.0|\n",
      "|9221083086|18.0|\n",
      "|9843425734|18.0|\n",
      "|1656582676|18.0|\n",
      "|2266999390|16.0|\n",
      "|3144537041|16.0|\n",
      "|0253301460|16.0|\n",
      "|1853980848|15.0|\n",
      "+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mt\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [user_id: string, avg: double]\n",
       "\u001b[36mquery\u001b[39m: \u001b[32mstreaming\u001b[39m.\u001b[32mStreamingQuery\u001b[39m = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@3790764f\n",
       "\u001b[36mres8_2\u001b[39m: \u001b[32mBoolean\u001b[39m = false"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val t = records.groupBy($\"user_id\")\n",
    "    .agg(avg($\"wordcount\").alias(\"avg\"))\n",
    "    .orderBy($\"avg\".desc)\n",
    "val query = t.writeStream\n",
    "  .trigger(Trigger.ProcessingTime(\"15 seconds\"))\n",
    "  .outputMode(\"complete\")\n",
    "  .format(\"console\")\n",
    "  .start()\n",
    "query.awaitTermination(50 * 1000)\n",
    "Thread.sleep(3 * 1000)\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---+---+\n",
      "|p50|p90|\n",
      "+---+---+\n",
      "+---+---+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----+------------------+\n",
      "| p50|               p90|\n",
      "+----+------------------+\n",
      "|13.5|27.733333333333334|\n",
      "|13.5|27.733333333333334|\n",
      "|13.5|27.733333333333334|\n",
      "+----+------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-----+------------------+\n",
      "|  p50|               p90|\n",
      "+-----+------------------+\n",
      "| 13.5|27.733333333333334|\n",
      "|15.75|              29.0|\n",
      "|15.75|              29.0|\n",
      "| 15.6|              29.0|\n",
      "| 13.5|27.733333333333334|\n",
      "+-----+------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+-----+------------------+\n",
      "|  p50|               p90|\n",
      "+-----+------------------+\n",
      "| 13.5|27.733333333333334|\n",
      "|15.75|              29.0|\n",
      "| 19.0|27.200000000000003|\n",
      "|16.75|             28.55|\n",
      "| 15.6|              29.0|\n",
      "| 19.0|27.200000000000003|\n",
      "| 13.5|27.733333333333334|\n",
      "+-----+------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+-----+------------------+\n",
      "|  p50|               p90|\n",
      "+-----+------------------+\n",
      "| 13.5|27.733333333333334|\n",
      "|15.75|              29.0|\n",
      "| 19.0|27.200000000000003|\n",
      "| 19.0|              33.2|\n",
      "|16.75|             28.55|\n",
      "| 19.0|              33.2|\n",
      "| 15.6|              29.0|\n",
      "| 19.0|              31.0|\n",
      "| 13.5|27.733333333333334|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mt\u001b[39m: \u001b[32mDataFrame\u001b[39m = [p50: double, p90: double]\n",
       "\u001b[36mquery\u001b[39m: \u001b[32mstreaming\u001b[39m.\u001b[32mStreamingQuery\u001b[39m = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@6d7ac677\n",
       "\u001b[36mres9_2\u001b[39m: \u001b[32mBoolean\u001b[39m = false"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val t = records.withColumn(\"time\", current_timestamp()).groupBy(window($\"time\", \"30 seconds\", \"10 seconds\"))\n",
    "    .agg(sketchCDF($\"wordcount\").alias(\"CDF\"))\n",
    "    .select(callUDF(\"p50\", $\"CDF\").alias(\"p50\"),\n",
    "            callUDF(\"p90\", $\"CDF\").alias(\"p90\"))\n",
    "val query = t.writeStream\n",
    "  .trigger(Trigger.ProcessingTime(\"20 seconds\"))\n",
    "  .outputMode(\"complete\")\n",
    "  .format(\"console\")\n",
    "  .start()\n",
    "query.awaitTermination(65 * 1000)\n",
    "Thread.sleep(3 * 1000)\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---+---+\n",
      "|_1 |_2 |\n",
      "+---+---+\n",
      "+---+---+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+----------+--------------------------------------------------------------------------------------------------------------------+\n",
      "|_1        |_2                                                                                                                  |\n",
      "+----------+--------------------------------------------------------------------------------------------------------------------+\n",
      "|0757325932|Vector((#Marianne,1), (#AAP,1))                                                                                     |\n",
      "|6927404733|Vector((#Marianne's,1), (#20+days,1), (#Crawford,1), (#allhours,1), (#Mix,1))                                       |\n",
      "|9431618928|Vector((#Lyme.,1), (#onlyfiveminutes,1))                                                                            |\n",
      "|1560754204|Vector((#U.S.,1), (#Herdays,1), (#Danvers,1))                                                                       |\n",
      "|6423284956|Vector((#first,,1), (#2years,1), (#Musgroves,1))                                                                    |\n",
      "|2187051561|Vector((#Lori,1), (#thistimeofyear,1))                                                                              |\n",
      "|7107658827|Vector((#Swedish,1), (#0,1), (#lessthan15,1))                                                                       |\n",
      "|8807165774|Vector((#Jennings,1), (#2010,1), (#TheNeuhausCollection-Truffles,1))                                                |\n",
      "|4306864580|Vector((#fivedollars,1), (#NON-RETURNABLE,1))                                                                       |\n",
      "|6689622873|Vector((#Anna,1), (#onlyforanhour,1), (#theRosingsparty,1), (#June13th1790,1))                                      |\n",
      "|4641263162|Vector((#Dew,1), (#DearEmma,1), (#ChanaMasala,1))                                                                   |\n",
      "|7766622678|Vector((#GoldenStateSignatureCollectionFruitGift,1), (#aboutatwelvemonthago,1), (#around70%,1), (#MissMainwaring,1))|\n",
      "|3521603525|Vector((#Harry,1))                                                                                                  |\n",
      "|2314980620|Vector((#GeorgeLesleysMarriage,1), (#Crema,1))                                                                      |\n",
      "+----------+--------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+----------+------------------------------------------------------------------------------------------------------+\n",
      "|_1        |_2                                                                                                    |\n",
      "+----------+------------------------------------------------------------------------------------------------------+\n",
      "|3157694572|Vector((#3,1), (#Sundayevening,1), (#Time,1))                                                         |\n",
      "|0757325932|Vector((#Marianne,1), (#AAP,1))                                                                       |\n",
      "|8461001396|Vector((#Allen's,1), (#Catherine's,1), (#Shropshire,1), (#aweekago,1), (#AgainCatherine,1))           |\n",
      "|6915409628|Vector((#April,1), (#3-pack,1), (#LISTENED,1))                                                        |\n",
      "|6927404733|Vector((#Marianne's,1), (#20+days,1), (#Crawford,1), (#allhours,1), (#Mix,1))                         |\n",
      "|9486120034|Vector((#LOL,1), (#Thornberry,1), (#Thorpe,1), (#March,1), (#threefeet,1))                            |\n",
      "|9431618928|Vector((#Lyme.,1), (#onlyfiveminutes,1))                                                              |\n",
      "|0824403620|Vector((#half,1), (#XXIIIMRS,1), (#110,1))                                                            |\n",
      "|4235617123|Vector((#lastChristmas,,1), (#afewmonths.,1), (#Sam'sClub,1), (#theInternationalInstant,1), (#Grey,1))|\n",
      "|2266999390|Vector((#Tilney's,1), (#CassandraAusten,1), (#February,1), (#BiddyHenshawe,1), (#Macdonald,1))        |\n",
      "|8453018869|Vector((#Thefirsttenminutes,1), (#500ml,1), (#theEastIndies,1))                                       |\n",
      "|9950933938|Vector((#Margaret,,1), (#aweekortwo,1))                                                               |\n",
      "|1560754204|Vector((#U.S.,1), (#Herdays,1), (#Danvers,1))                                                         |\n",
      "|1142011669|Vector((#Fairfax,1))                                                                                  |\n",
      "|8603821315|Vector((#AWFUL,1), (#Norland,1))                                                                      |\n",
      "|9018838890|Vector((#Cottager,1), (#Anhour,1))                                                                    |\n",
      "|6423284956|Vector((#first,,1), (#2years,1), (#Musgroves,1))                                                      |\n",
      "|2187051561|Vector((#Lori,1), (#thistimeofyear,1))                                                                |\n",
      "|8589067213|Vector((#11weekold,1), (#64-6221541,1))                                                               |\n",
      "|5727599919|Vector((#E.,1), (#Italian,1), (#Garlic&Pepper,1))                                                     |\n",
      "+----------+------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+----------+------------------------------------------------------------------------------------------------------+\n",
      "|_1        |_2                                                                                                    |\n",
      "+----------+------------------------------------------------------------------------------------------------------+\n",
      "|3157694572|Vector((#3,1), (#Sundayevening,1), (#Time,1))                                                         |\n",
      "|0757325932|Vector((#Marianne,1), (#AAP,1))                                                                       |\n",
      "|5107864389|Vector((#Edward's,1), (#Hall,1), (#MissCrawford,1), (#October,1), (#55,1))                            |\n",
      "|8461001396|Vector((#Allen's,1), (#Catherine's,1), (#Shropshire,1), (#aweekago,1), (#AgainCatherine,1))           |\n",
      "|6915409628|Vector((#April,1), (#3-pack,1), (#LISTENED,1))                                                        |\n",
      "|0072980186|Vector((#2,1), (#MissThorpe's,1), (#asecondspring,1))                                                 |\n",
      "|8598722953|Vector((#two,1), (#Merit,1), (#over30years,1))                                                        |\n",
      "|6927404733|Vector((#Marianne's,1), (#20+days,1), (#Crawford,1), (#allhours,1), (#Mix,1))                         |\n",
      "|9486120034|Vector((#LOL,1), (#Thornberry,1), (#Thorpe,1), (#March,1), (#threefeet,1))                            |\n",
      "|1183618331|Vector((#MrsCroft's,1), (#Smith,1), (#Propriety,1), (#midnight,1), (#acoupleofweeks,1))               |\n",
      "|4596813825|Vector((#Mine,1))                                                                                     |\n",
      "|9431618928|Vector((#Lyme.,1), (#onlyfiveminutes,1))                                                              |\n",
      "|0824403620|Vector((#half,1), (#XXIIIMRS,1), (#110,1))                                                            |\n",
      "|7800303782|Vector((#thefifteenthcentury,1), (#AWFUL,1))                                                          |\n",
      "|4235617123|Vector((#lastChristmas,,1), (#afewmonths.,1), (#Sam'sClub,1), (#theInternationalInstant,1), (#Grey,1))|\n",
      "|9234174239|Vector((#_she#_,1), (#DukeofBuckingham,1), (#thisveryday,1), (#Foundation,1))                         |\n",
      "|6174362090|Vector((#LadyDalrymple,1), (#Mama,1), (#CousinMusgrove,1), (#over$6,1), (#somemonths,1))              |\n",
      "|2266999390|Vector((#Tilney's,1), (#CassandraAusten,1), (#February,1), (#BiddyHenshawe,1), (#Macdonald,1))        |\n",
      "|4916181798|Vector((#Bristol,1), (#Alarming,1))                                                                   |\n",
      "|8453018869|Vector((#Thefirsttenminutes,1), (#500ml,1), (#theEastIndies,1))                                       |\n",
      "+----------+------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtka\u001b[39m: \u001b[32mTypedColumn\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m), \u001b[32mArray\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)]] = topkaggregator()\n",
       "\u001b[36mt\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = [_1: string, _2: string]\n",
       "\u001b[36mquery\u001b[39m: \u001b[32mstreaming\u001b[39m.\u001b[32mStreamingQuery\u001b[39m = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@1604614c\n",
       "\u001b[36mres10_3\u001b[39m: \u001b[32mBoolean\u001b[39m = false"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tka = new org.isarnproject.sketches.udaf.TopKAggregator[(String, String)](_._2).toColumn\n",
    "val t = records\n",
    "  .select($\"user_id\",\n",
    "          explode(split($\"text\", \" \")).alias(\"word\"))\n",
    "  .as[(String, String)]\n",
    "  .filter(_._2(0)=='#')\n",
    "  .groupByKey { case (id, _) => id }.agg(tka)\n",
    "  .map { case (id, tk) => (id, tk.toVector.toString)}\n",
    "val query = t.writeStream\n",
    "  .trigger(Trigger.ProcessingTime(\"20 seconds\"))\n",
    "  .option(\"truncate\", false)\n",
    "  .outputMode(\"complete\")\n",
    "  .format(\"console\")\n",
    "  .start()\n",
    "query.awaitTermination(65 * 1000)\n",
    "Thread.sleep(3 * 1000)\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mobject\u001b[39m \u001b[36mwindowing\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object windowing {\n",
    "    import java.sql.Timestamp\n",
    "    import java.time.Instant\n",
    "    def windowBy[R](f:R=>Timestamp, width: Int) = {\n",
    "        val w = width.toLong * 1000L\n",
    "        (row: R) => {\n",
    "            val tsCur = f(row)\n",
    "            val msCur = tsCur.getTime()\n",
    "            val msLB = (msCur / w) * w\n",
    "            val instLB = Instant.ofEpochMilli(msLB)\n",
    "            val instUB = Instant.ofEpochMilli(msLB+w)\n",
    "            (Timestamp.from(instLB), Timestamp.from(instUB))\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---+---+\n",
      "|_1 |_2 |\n",
      "+---+---+\n",
      "+---+---+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-------------------+----------------------------------------------------------------------------+\n",
      "|_1                 |_2                                                                          |\n",
      "+-------------------+----------------------------------------------------------------------------+\n",
      "|2018-09-27 18:02:00|Vector((#PETE,2), (#Nutiva,1), (#Fairfax,1), (#H.Halton,1), (#Afewmonths,1))|\n",
      "+-------------------+----------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-------------------+----------------------------------------------------------------------------+\n",
      "|_1                 |_2                                                                          |\n",
      "+-------------------+----------------------------------------------------------------------------+\n",
      "|2018-09-27 18:02:00|Vector((#PETE,2), (#Nutiva,1), (#Fairfax,1), (#H.Halton,1), (#Afewmonths,1))|\n",
      "+-------------------+----------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+-------------------+--------------------------------------------------------------------------------+\n",
      "|_1                 |_2                                                                              |\n",
      "+-------------------+--------------------------------------------------------------------------------+\n",
      "|2018-09-27 18:03:00|Vector((#Iddesleigh,2), (#49.99,1), (#Yates.,1), (#MrsCroft,1), (#theevening,1))|\n",
      "|2018-09-27 18:02:00|Vector((#PETE,2), (#Nutiva,1), (#Fairfax,1), (#H.Halton,1), (#Afewmonths,1))    |\n",
      "+-------------------+--------------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------------------------------------------------------------------+\n",
      "|_1                 |_2                                                                             |\n",
      "+-------------------+-------------------------------------------------------------------------------+\n",
      "|2018-09-27 18:03:00|Vector((#Iddesleigh,2), (#Gardiner,,2), (#49.99,1), (#Yates.,1), (#MrsCroft,1))|\n",
      "|2018-09-27 18:02:00|Vector((#PETE,2), (#Nutiva,1), (#Fairfax,1), (#H.Halton,1), (#Afewmonths,1))   |\n",
      "+-------------------+-------------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+-------------------+---------------------------------------------------------------------------------+\n",
      "|_1                 |_2                                                                               |\n",
      "+-------------------+---------------------------------------------------------------------------------+\n",
      "|2018-09-27 18:03:00|Vector((#Iddesleigh,2), (#Gardiner,,2), (#Willoughby,2), (#49.99,1), (#Yates.,1))|\n",
      "|2018-09-27 18:02:00|Vector((#PETE,2), (#Nutiva,1), (#Fairfax,1), (#H.Halton,1), (#Afewmonths,1))     |\n",
      "+-------------------+---------------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+-------------------+---------------------------------------------------------------------------------------+\n",
      "|_1                 |_2                                                                                     |\n",
      "+-------------------+---------------------------------------------------------------------------------------+\n",
      "|2018-09-27 18:03:00|Vector((#Iddesleigh,2), (#Gardiner,,2), (#Willoughby,2), (#49.99,1), (#Yates.,1))      |\n",
      "|2018-09-27 18:04:00|Vector((#Elizabeth,,1), (#HERPRESENT,1), (#upforhours,1), (#Martin,1), (#NurseRooke,1))|\n",
      "|2018-09-27 18:02:00|Vector((#PETE,2), (#Nutiva,1), (#Fairfax,1), (#H.Halton,1), (#Afewmonths,1))           |\n",
      "+-------------------+---------------------------------------------------------------------------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 7\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18/09/27 18:03:22 WARN JobProgressListener: Task start for unknown stage 115\n",
      "18/09/27 18:03:22 WARN TaskSetManager: Lost task 121.0 in stage 115.0 (TID 9637, localhost, executor driver): TaskKilled (stage cancelled)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mwindowBy60\u001b[39m: (\u001b[32mjava\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mTimestamp\u001b[39m, \u001b[32mString\u001b[39m) => (\u001b[32mjava\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mTimestamp\u001b[39m, \u001b[32mjava\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mTimestamp\u001b[39m) = <function1>\n",
       "\u001b[36mtka\u001b[39m: \u001b[32mTypedColumn\u001b[39m[(\u001b[32mjava\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mTimestamp\u001b[39m, \u001b[32mString\u001b[39m), \u001b[32mArray\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)]] = topkaggregator()\n",
       "\u001b[36mt\u001b[39m: \u001b[32mDataset\u001b[39m[(\u001b[32mjava\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mTimestamp\u001b[39m, \u001b[32mString\u001b[39m)] = [_1: timestamp, _2: string]\n",
       "\u001b[36mquery\u001b[39m: \u001b[32mstreaming\u001b[39m.\u001b[32mStreamingQuery\u001b[39m = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@34fa0ca0\n",
       "\u001b[36mres12_4\u001b[39m: \u001b[32mBoolean\u001b[39m = false"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val windowBy60 = windowing.windowBy[(java.sql.Timestamp, String)](_._1, 60)\n",
    "val tka = new org.isarnproject.sketches.udaf.TopKAggregator[(java.sql.Timestamp, String)](_._2).toColumn\n",
    "val t = records\n",
    "  .select(current_timestamp().alias(\"time\"),\n",
    "          explode(split($\"text\", \" \")).alias(\"word\"))\n",
    "  .as[(java.sql.Timestamp, String)]\n",
    "  .filter(_._2(0)=='#')\n",
    "  .groupByKey(windowBy60).agg(tka)\n",
    "  .map { case (tw, tk) => (tw._2, tk.toVector.toString)}\n",
    "val query = t.writeStream\n",
    "  .trigger(Trigger.ProcessingTime(\"20 seconds\"))\n",
    "  .option(\"truncate\", false)\n",
    "  .outputMode(\"complete\")\n",
    "  .format(\"console\")\n",
    "  .start()\n",
    "query.awaitTermination(125 * 1000)\n",
    "Thread.sleep(3 * 1000)\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
